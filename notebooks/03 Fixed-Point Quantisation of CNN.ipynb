{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fixed-Point Quantisation of CNN\n",
    "\n",
    "This tutorial introduces fixed-point quantisation of CNN using our Plumber tool-chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fixed point or Q representation\n",
    "\n",
    "To represent a non-integer or a fractional number a developer usually has two options. The first one is to use floating point representation, which supports a trade-off between numerical range and precision. The name gives out the main property, the point separating the integer part and fractional point floats, rather than stays fixed. However, this data-type and its arithmetic is challenging to implement in hardware with optimal performance, unless the processing device has enough space and resources for a dedicated *F*loating *P*oint *U*nit (FPU).\n",
    "\n",
    "That is why in most of low-power, low-performance embeded devices that might require constant resolution we find fixed point representation or *Q*-representation. A non-integer number is then usually represented with total fixed number of bits on which we can operate, be it 16, 32 or 64 etc. These bits are then split into two parts, with an imaginary point separating them. The first part is for the _Integer_ part (IP) and the second one is _Fractional_ part. For example, given that we are operating on 16 bits in total, a Q16 number has 16 fractional bits; a Q2.14 number has 2 integer bits and 14 fractional bits. Note, that to represent signed numbers, we usually need to assign one more bit from the integer part to determine the number being signed.\n",
    "\n",
    "This representation has its pros and its cons, on one hand it is very easy to [implement](https://en.wikipedia.org/wiki/Q_(number_format)#Math_operations) it in low-level designs, giving improved performance and lower power consumption, the issue remains its precision. Let's see that on an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.11111111 1.22222222 1.33333333 1.44444444 1.55555556\n",
      " 1.66666667 1.77777778 1.88888889 2.        ]\n",
      "[1.  1.  1.  1.5 1.5 1.5 1.5 2.  2.  2. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Fractional bits\n",
    "f = 2\n",
    "\n",
    "#Introduce scale by which we are going to scale the output/input\n",
    "scale = 1 << f\n",
    "\n",
    "a = np.linspace(1,2,10)\n",
    "a_fix = np.round(a*f)*(1.0/f)\n",
    "\n",
    "print(a)\n",
    "print(a_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the range of the numbers and it's resulution e.g.: in *U* (Unsigned) Q2.14 and *S* (Signed, aka one bit from the integer part will represent the sign) Q8.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UQ2.14\n",
      "Range is: 0 to 3.99993896484375\n",
      "Resolution is: 6.103515625e-05\n",
      "SQ8.8\n",
      "Range is: -128 to 127.99609375\n",
      "Resolution is: 0.00390625\n"
     ]
    }
   ],
   "source": [
    "# In total we have 16 bits to operate on\n",
    "# UQ2.14\n",
    "i = 2\n",
    "f = 14\n",
    "print(\"UQ2.14\")\n",
    "print(\"Range is: {} to {}\".format(0, 2**i-2**(-f)))\n",
    "print(\"Resolution is: {}\".format(2**(-f)))\n",
    "\n",
    "# SQ8.8\n",
    "i = 8\n",
    "f = 8\n",
    "print(\"SQ8.8\")\n",
    "print(\"Range is: {} to {}\".format(-2**(i-1), 2**(i-1)-2**(-f)))\n",
    "print(\"Resolution is: {}\".format(2**(-f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this toy example you can see how much the resolution and range can differ based on the dedicated IP and FP bits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Float to Q\n",
    "To convert the number from floating point to Qm.n format: \n",
    "1. Multiply the floating point number by 2<sup>n</sup> - which is basically a shift of a number left by *n* places\n",
    "2. Round to the nearest integer\n",
    "\n",
    "##### Q to float\n",
    "1. Convert the number to floating point as if it was an integer, in other words remove the binary point\n",
    "2. Multiply by 2<sup>-n</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number in Q format is: 538 and it's binary representation is then 0b1000011010\n",
      "The number back in float is: 2.1015625\n"
     ]
    }
   ],
   "source": [
    "# Given that we have UQ8.8 format (UQm.n) \n",
    "m = 8\n",
    "n = 8\n",
    "f = 2.1\n",
    "q = f * 2**n\n",
    "rounded = round(q)\n",
    "print(\"The number in Q format is: {} and it's binary representation is then {}\".format(rounded, bin(rounded)))\n",
    "print(\"The number back in float is: {}\".format(rounded*2**(-n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another problem that occurs with this representation, if you are performing conversion from one format to another you are loosing precision and eventually, accuracy. Keep in mind that when you are performing arithmetic operations, you have to saturate the output to fit into the bounds of sensible representation.\n",
    "\n",
    "#### Arithmetic operations\n",
    "One big advantage of fixed point representation is that, arithmetic functions can be performed directly on an an ALU. Given that we have UQ8.8 representation we can demonstrate it. \n",
    "\n",
    "##### Addition & Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The addition back in float is: 4.40234375, using floats: 4.4\n",
      "The subtraction back in float is: -0.19921875, using floats: -0.19999999999999973\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "f = 8\n",
    "a = 2.1\n",
    "b = 2.3\n",
    "a_fp = round(a * 2**f)\n",
    "b_fp = round(b * 2**f)\n",
    "c_fp = a_fp + b_fp\n",
    "d_fp = a_fp - b_fp\n",
    "print(\"The addition back in float is: {}, using floats: {}\".format(c_fp*2**(-f),a+b))\n",
    "print(\"The subtraction back in float is: {}, using floats: {}\".format(d_fp*2**(-f),a-b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiplication\n",
    "Multiplication is little bit complicated and we have to introduce the concept of saturation. In case of overflow (which can of course happen in case of addition and subtraction) we have to keep in mind to clamp the result between sensible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multiplication back in float is: 4.8359375, using floats: 4.83\n"
     ]
    }
   ],
   "source": [
    "def saturate(x):\n",
    "    if x>0xFFFF:\n",
    "        return 0xFFFF\n",
    "    elif x<0x0:\n",
    "        return 0x0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "i = 8\n",
    "f = 8\n",
    "K = 1 << (f-1)\n",
    "\n",
    "a = 2.1\n",
    "b = 2.3\n",
    "\n",
    "a_fp = round(a * 2**f)\n",
    "b_fp = round(b * 2**f)\n",
    "\n",
    "temp = a_fp * b_fp\n",
    "temp += K\n",
    "result = saturate(temp >> f)\n",
    "print(\"The multiplication back in float is: {}, using floats: {}\".format(result*2**(-f),a*b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division\n",
    "Again using the same concepts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The division back in float is: 0.9153656886672326, using floats: 0.9130434782608696\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "f = 8\n",
    "\n",
    "a = 2.1\n",
    "b = 2.3\n",
    "\n",
    "a_fp = round(a * 2**f)\n",
    "b_fp = round(b * 2**f)\n",
    "\n",
    "# Pre-multiply by the base (Upscale to Q24 so that the result will be in Q16 format) \n",
    "temp = a_fp << f;\n",
    "# Rounding: mid values are rounded up (down for negative values)\n",
    "# OR compare most significant bits i.e. if (((temp >> 31) & 1) == ((b >> 15) & 1))\n",
    "if((temp >= 0 and b_fp >= 0) or (temp < 0 and b_fp < 0)):   \n",
    "    temp += b_fp / 2;  \n",
    "else: \n",
    "    temp -= b_fp / 2;    \n",
    "\n",
    "result = temp / b_fp;\n",
    "print(\"The division back in float is: {}, using floats: {}\".format(result*2**(-f),a/b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
