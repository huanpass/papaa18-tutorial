{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fixed-Point Quantisation of CNN\n",
    "\n",
    "This tutorial introduces fixed-point quantisation of CNN using our Plumber tool-chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fixed point or Q representation\n",
    "\n",
    "To represent a non-integer or a fractional number a developer usually has two options. The first one is to use floating point representation, which supports a trade-off between numerical range and precision. The name gives out the main property, the point separating the integer part and fractional point floats, rather than stays fixed. However, this data-type and its arithmetic is challenging to implement in hardware with optimal performance, unless the processing device has enough space and resources for a dedicated *F*loating *P*oint *U*nit (FPU).\n",
    "\n",
    "That is why in most of low-power, low-performance embeded devices that might require constant resolution we find fixed point representation or *Q*-representation. A non-integer number usually has a total fixed number of bits on which we can operate, be it 16, 32 or 64 etc. These bits are then split into two parts, with an imaginary point separating  The first part is for the _Integer_ part (IP) and the second one is _Fractional_ part. For example, given that we are operating on 16 bits in total, a Q16 number has 16 fractional bits; a Q2.14 number has 2 integer bits and 14 fractional bits. Note, that to represent signed numbers, we usually need to assign one more bit from the integer part to determine the number being signed.\n",
    "\n",
    "This representation has its pros and its cons, on one hand it is very easy to [implement](https://en.wikipedia.org/wiki/Q_(number_format)#Math_operations) it in low-level designs, giving improved performance and lower power consumption, the issue remains its precision. Let's see that on an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.11111111 1.22222222 1.33333333 1.44444444 1.55555556\n",
      " 1.66666667 1.77777778 1.88888889 2.        ]\n",
      "[1.  1.  1.  1.5 1.5 1.5 1.5 2.  2.  2. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Fractional bits\n",
    "f = 2\n",
    "\n",
    "#Introduce scale by which we are going to scale the output/input\n",
    "scale = 1 << f\n",
    "\n",
    "a = np.linspace(1,2,10)\n",
    "a_fix = np.round(a*f)*(1.0/f)\n",
    "\n",
    "print(a)\n",
    "print(a_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the range of the numbers and it's resulution e.g.: in *U* (Unsigned) Q2.14 and *S* (Signed, aka one bit from the integer part will represent the sign) Q8.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UQ2.14\n",
      "Range is: 0 to 3.99993896484375\n",
      "Resolution is: 6.103515625e-05\n",
      "SQ8.8\n",
      "Range is: -128 to 127.99609375\n",
      "Resolution is: 0.00390625\n"
     ]
    }
   ],
   "source": [
    "# In total we have 16 bits to operate on\n",
    "# UQ2.14\n",
    "i = 2\n",
    "f = 14\n",
    "print(\"UQ2.14\")\n",
    "print(\"Range is: {} to {}\".format(0, 2**i-2**(-f)))\n",
    "print(\"Resolution is: {}\".format(2**(-f)))\n",
    "\n",
    "# SQ8.8\n",
    "i = 8\n",
    "f = 8\n",
    "print(\"SQ8.8\")\n",
    "print(\"Range is: {} to {}\".format(-2**(i-1), 2**(i-1)-2**(-f)))\n",
    "print(\"Resolution is: {}\".format(2**(-f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this toy example you can see how much the resolution can differ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Float to Q\n",
    "To convert the number from floating point to Qm.n format: \n",
    "1. Multiply the floating point number by 2<sup>n</sup> - which is basically a shift of a number left by *n* places\n",
    "2. Round to the nearest integer\n",
    "\n",
    "##### Q to float\n",
    "1. Convert the number to floating point as if it was an integer, in other words remove the binary point\n",
    "2. Multiply by 2<sup>-n</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number in Q format is: 538 and it's binary representation is then 0b1000011010\n",
      "The number back in float is: 2.1015625\n"
     ]
    }
   ],
   "source": [
    "# Given that we have UQ8.8 format \n",
    "m = 8\n",
    "n = 8\n",
    "f = 2.1\n",
    "q = f * 2**n\n",
    "rounded = round(q)\n",
    "print(\"The number in Q format is: {} and it's binary representation is then {}\".format(rounded, bin(rounded)))\n",
    "print(\"The number back in float is: {}\".format(rounded*2**(-n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another problem that occurs with this representation, if you are performing conversion from one format to another you are loosing precision and eventually, accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
