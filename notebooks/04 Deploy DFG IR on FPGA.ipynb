{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy DFG IR on FPGA\n",
    "\n",
    "This tutorial continues, with how to, finally deploy the algorithm, in this case our face detaction SSD model onto an FPGA. We have talked about the network itself, Tensorflow as a *DSL* and we are going to finish off by using the platform that we have introduced in previous tutorials to take this network and actually deploy it onto the FPGA.\n",
    "\n",
    "This tutorial is organised as follows:\n",
    "\n",
    "1. [Freezing a model](#Freezing-a-model)\n",
    "2. [Creating a DFG](#Creating-a-DFG)\n",
    "3. [Optimizing DFG](#Optimizing-DFG)\n",
    "4. [Hardware Deployment](#Hardware-Deployment)\n",
    "5. [Importing DFG into raintime](#Importing-DFG-into-raintime)\n",
    "6. [Compilation Observation](#Compilation-Observation)\n",
    "\n",
    "\n",
    "### Intended Outcomes:\n",
    "\n",
    "1. Learn and understand how the compilation process could be split up for your research interests\n",
    "2. Learn how to use our tool flow to deploy a model onto FPGA\n",
    "\n",
    "Given that you have installed `Plumber` in the Tutorial 1, we are now going to use it to generate a *D*ata-*F*low *G*raph (DFG) that can be passed down the platform to reach the final execution on FPGA and CPU. After this lab you should understand the concept of multi-stage compilation down to the FPGA level or be inspired how to translate this process into your personal projects. \n",
    "\n",
    "Just for a quick summary and recapitulation, the platform itself consists of multiple parts: *Plumber* is a web-based application capable of taking a templated description of a machine learning algorithm, optimize it and create a DFG that is then passed into *raintime*. *raintime* then instantiates computation nodes, either processed in a CPU or offloaded to a FPGA accelerator. *rainman* then takes the FPGA templates and synthesises them on the device itself, while interconnecting with the nodes instantiated on the CPU. All can be visualised in a simple diagram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flowchart.png](../data/figs/platform_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as to go deeper into the compilation process it can be separated into two parts. First is a software call via *Plumber*. The first layer of the platform gets a description of CNN which is then passed into DFG intermediate representation (IR). It then optimizes it in software and later in hardware which is going to generate a `*.json` construct which is going to be a guide for actual hardware design. That description is then used to create a bit-stream by using Vivado environment. All the information and capabilities of our platform can be also found on this [link](https://corerain.github.io/plumber-docs/topics/commands.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then follows the software call which has multiple steps which we are going to discuss below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get started with the SSD example, make sure that you have the checkpoint files of your model and a `plumber_cli` installed in your virtual environment. The checkpoint fiels are already downloaded for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can simply use the `plumber_cli` to step-by-step to create a DFG that can be loaded on FPGA. So please create a separate terminal window and navigate to the tutorial directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing a model\n",
    "Make sure that your checkpoint files generated after training/retraining session contain these files: \n",
    "\n",
    "- `checkpoint`: a file that contains meta information, data files and index file about the checkpoint directory\n",
    "- `*.meta`: the meta information about your model\n",
    "- `*.data`: weights data\n",
    "- `*.index`: the index file\n",
    "\n",
    "These files are now going to be used to be imported into `Plumber` and consequently converted into a representation that the platform *understands* and can optimise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.5.0\r\n",
      "Usage: plumber_cli freeze [OPTIONS] MODEL_DIR\r\n",
      "\r\n",
      "Error: Invalid value for \"model_dir\": Path \"model/ssd_ckpt\" does not exist.\r\n"
     ]
    }
   ],
   "source": [
    "! plumber_cli freeze model/ssd_ckpt -d model/ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model/ssd_ckpt/`: is the checkpoint directory\n",
    "- `model/ssd/`: is the output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DFG\n",
    "\n",
    "Out of these files that you have created you can create a raw Data-Flow graph, again by using `plumber_cli`. This command actually parse the content from the frozen TensorFlow model and generates a corresponding DFG. You can use the visualisation utility provided in tutorial 2 to see what the generated DFG, `model/ssd/ssd_dfg.pbtxt` in the following case, looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.5.0\r\n",
      "Usage: plumber_cli dfg [OPTIONS]\r\n",
      "\r\n",
      "Error: Invalid value for \"--model-file\" / \"-m\": Path \"model/ssd/model.pb\" does not exist.\r\n"
     ]
    }
   ],
   "source": [
    "!plumber_cli dfg \\\n",
    "    --model-file=model/ssd/model.pb \\\n",
    "    --dfg-bin-file=model/ssd/model_dfg.pb \\\n",
    "    --dfg-text-file=model/ssd/ssd_dfg.pbtxt \\\n",
    "    --dfg-data-file=model/ssd/ssd_dfg.h5 \\\n",
    "    --input-image-shape=1,256,256,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model/ssd/model.pb`: is the Plumber file describing the network as a Plumber binary file\n",
    "- `model/ssd/model_dfg.pb`: is the Plumber template for a DFG\n",
    "- `model/ssd/ssd_dfg.pbtxt`: is the description of the DFG in a text format\n",
    "- `model/ssd/ssd_dfg.h5`: is a data-file describing input/output sizes, important for random data generation or weights extraction\n",
    "- `1,256,256,3`: is an input image shape, in our case 256x256 images with three channels with one image per batch, n.b.: the format is Batch Size, Height, Width, Number of Channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing DFG\n",
    "\n",
    "DFG should be optimised before hardware deployment. DFG optimisation is performed in two steps: platform-independet and platform-dependent optimisation. Platform-independet optimisation improves the efficiency of the model without knowing the platform specification, while platform-dependent optimisation takes that information into account. Both steps are callable from `plumber_cli`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform-Independent Optimisation\n",
    "\n",
    "`dfg_opt` optimises an input DFG in a platform-independent style. It mainly quantises model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.5.0\n",
      "Usage: plumber_cli dfg_opt [OPTIONS]\n",
      "\n",
      "Error: Invalid value for \"--dfg-file\" / \"-f\": Path \"model/ssd/model_dfg.pb\" does not exist.\n"
     ]
    }
   ],
   "source": [
    "!plumber_cli dfg_opt \\\n",
    "    --dfg-file=model/ssd/model_dfg.pb \\\n",
    "    --dfg-data-file=model/ssd/ssd_dfg.h5 \\\n",
    "    --opt-dfg-file=model/ssd/ssd_opt_dfg.pbtxt \\\n",
    "    --logdir=model/ssd/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will now take the original DFG described in `tmp/ssd_dfg.pb` and optimize it to maximaise the gain from our platform: \n",
    "\n",
    "- `model/ssd/model_dfg.pb`: is the previously generated DFG file\n",
    "- `model/ssd/ssd_dfg.h5`: is the data file that we have created in the previous step\n",
    "- `model/ssd/ssd_opt_dfg.pbtxt`: this is the new, optimised, pbtxt\n",
    "- `model/ssd/logs`: this is the logging directory\n",
    "\n",
    "now let's move to the next step, which actually results in an execution on embedded system with FPGA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to skip these two steps you can also find the data generated at this link: [Link](https://s3-eu-west-1.amazonaws.com/coreraincifardata/ssd_6b_data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform-Dependent Optimisation\n",
    "\n",
    "`hdl_opt` performs platform-dependent optimisation. It takes a board specification file and a platform-independently optimised DFG as input, and produces a further optimised DFG and a configuration file that specifies hardware design parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.5.0\r\n",
      "Error: no such option: --dfg-file\r\n"
     ]
    }
   ],
   "source": [
    "! plumber_cli hdl_opt \\\n",
    "    data/boards/rainman_board_v2.pbtxt \\\n",
    "    --dfg-file=/model/ssd/ssd_opt_dfg.pbtxt \\\n",
    "    --dfg-data-file=/model/ssd/ssd_dfg.h5 \\\n",
    "    --opt-dfg-file=/model/ssd/ssd_hdl_dfg.pbtxt \\\n",
    "    --logdir=/model/ssd/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, `data/boards/rainman_board_v2.pbtxt` is a board specification file that specifies our Rainman V2 board. It just specifies the number of each type of resource on our targeting board.\n",
    "\n",
    "```protobuf\n",
    "name: \"RAINMAN_BOARD_V2\"\n",
    "num_lut: 218600\n",
    "num_ff: 437200\n",
    "num_bram: 545\n",
    "num_dsp: 900\n",
    "```\n",
    "\n",
    "The optimisation procedure will try to fuse operators, allocate the execution device for each operation, and explore the design space. You can check the progress through its verbose output.\n",
    "\n",
    "`model/ssd/ssd_hdl_dfg.pbtxt` is the optimised DFG, and in `/model/ssd/logs` you can locate a file called `hdl_params.json` that contains hardware design parameters. This JSON file will be further utilised to generated bitstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Deployment\n",
    "\n",
    "To generate the bitstream, we should provide the `hdl_params.json` to the `gen` command. `gen` will call the FPGA synthesis tool-chain to produce a bitstream. Since we don't include any FPGA tool in the virtual machine or JupyterHub, we simply present the command and its outcome:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing DFG into raintime\n",
    "\n",
    "Just as a quick recap: `raintime` is a software runtime library for processing CNNs on embedded FPGA systems. Computation nodes in a CNN can either be processed in CPU or offloaded to the FPGA accelerator design built by `rainman`. It also has several parts, it can be summarised in a diagram without going into too much detail: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![raintime.png](../data/figs/raintime.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes themselves are already implemented in raintime, but we need to streamline the execution and say which data we want to extract etc. In later versions this step is going to be completely automatic, at the moment we have to write a short demo.\n",
    "\n",
    "If we were about to write the demo in `raintime`, to execute the demo on FPGA it would have several important steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C++\n",
    "  int batch_size = 1;\n",
    "  int n_channels = 3;\n",
    "  int img_size = 265\n",
    "\n",
    "  // Load image\n",
    "  cv::Mat image;\n",
    "    image = cv::imread(argv[1], cv::CV_LOAD_IMAGE_COLOR);\n",
    "    \n",
    "  // Reorder the pixel values from the default ordering of opencv\n",
    "  std::vector<uint8_t> converted;\n",
    "  auto image_pointer = image.ptr();\n",
    "  for (size_t i = 0; i < n_channels; i++) {\n",
    "    for (size_t j = 0; j < img_size * img_size; j++) {\n",
    "      converted[j + img_size * img_size * i] =  image[n_channels * j + i];\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Load DFGDef\n",
    "  auto dfg_def = LoadDFGDefFromFile(dfg_file_name);\n",
    "\n",
    "  // Use the integrated builder to build the graph and make abstractions to connect the CPU and FPGA\n",
    "  *dfg = DFGBuilder(dfg_def).Build();\n",
    "\n",
    "  // Load constant data map, including weights and biases\n",
    "  *data_map = new DFGDataMap;\n",
    "  (*data_map)->LoadFromDir(data_dir);\n",
    "  \n",
    "  \n",
    "  std::vector<int> dims;\n",
    "  dims.push_back(n_channels);\n",
    "  dims.push_back(img_size);\n",
    "  dims.push_back(img_size);\n",
    "  dims.push_back(batch_size);\n",
    "  \n",
    "  \n",
    "  // Load input data-map into the DFG, without any particular pre-processing optimisations\n",
    "  DFGDataMap *input_data_map = new DFGDataMap;\n",
    "    input_data_map->LoadImage(converted, image_size, n_channels,\n",
    "                              \"input_tensor\", dims, \"no\");\n",
    "                              \n",
    "  // Extract the output data map from the runner, in this case the \n",
    "  auto output_data_map = runner->Run(dfg, data_map, input_data_map, true);\n",
    "  auto output_data = output_data_map->get(\"Predictions\").second;\n",
    "\n",
    "\n",
    "  std::cout<<\"The number of detected faces: \"<<output_data_map.size()<<std::endl;\n",
    "  \n",
    "  //House-keeping\n",
    "  delete input_data_map;\n",
    "  delete output_data_map;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished writing the demo, then you would have to compile your design, on the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step Compilation Observation\n",
    "\n",
    "This is fairly easy, `raintime` has several settings how to compile a project, but we will try to avoid details. Once connected to the board with preinstalled OS and a correct `BOOT.bin`, you would clone the raintime project with your demo and compile it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ git clone https://github.com/corerain/raintime.git\n",
    "$ cd raintime\n",
    "$ mkdir build && cd build\n",
    "# Create the compiling structure through CMake and specify the number of fraction bits (FB) for a 32 bit representation\n",
    "$ cmake .. -DCMAKE_BUILD_TYPE=Release -DDEF_FIXED_NUM_FB_32=20 -DBUILD_TESTS=ON\n",
    "$ make\n",
    "$ ./your_demo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and viola! You have described an algorithm in Python/Tensorflow and now you are executing it on FPGA, great isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "\n",
    "Remember the fixed point representation from the previous tutorial? It obviously also affects the resources used in addition to accuracy and speed of execution. Let's also look at how many resources were used in each representation (32-bits and 16-bits):\n",
    "\n",
    "| SSD Demo          | 32-bits | 16-bits |\n",
    "|-------------------|---------|---------|\n",
    "| Registers         | 280871  | 92780   |\n",
    "| Block Memory bits | 12Mb    | 6349Kb  |\n",
    "| DSP Blocks        | 168     | 150     |\n",
    "\n",
    "you can see that the amount of registers decreases approximately three fold and block memory usage decreases approximately two fold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The process up-to raintime is also available as a web-application on: [Link](http://corerain1.corerain.com:5005/), where you can not only view the SSD demo but also others. Below is the Corerain's team. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![team.jpeg](../data/figs/team.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Or you can see a video of the demonstration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"../data/figs/face_detecion.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"../data/figs/face_detecion.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Contact\n",
    "\n",
    "If you would like to discover more please do not hesitate to contact us at:\n",
    "\n",
    "-   Professor Wayne Luk (w.luk@ic.ac.uk)\n",
    "\n",
    "-   Martin Ferianc (martin.ferianc@corerain.com)\n",
    "\n",
    "-   Ruizhe (Vincent) Zhao (vincent.zhao@corerain.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
