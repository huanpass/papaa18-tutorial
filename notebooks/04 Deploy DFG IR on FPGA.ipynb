{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy DFG IR on FPGA\n",
    "\n",
    "This tutorial continues, with how to, finally deploy the algorithm, in this case our face detaction SSD model onto an FPGA. We have talked about the network itself, Tensorflow as a *DSL* and we are going to finish off by using the platform that we have introduced in previous tutorials to take this network and actually deploy it onto the FPGA.\n",
    "\n",
    "Given that you have installed `plumber` in the Tutorial 1, we are now going to use it to generate a *D*ata-*F*low *G*raph (DFG) that can be passed down the platform to reach the final execution on FPGA and CPU. \n",
    "\n",
    "Just for a quick summary, the platform itself consists of multiple parts: *plumber* is a web-based application capable of taking a templated description of a machine learning algorithm, optimize it and create a DFG that is then passed into *raintime*. *raintime* then instantiates computation nodes, either processed in a CPU or offloaded to a FPGA accelerator. *rainman* then takes the FPGA templates and synthesises them on the device itself, while interconnecting with the nodes instantiated on the CPU. All can be visualised in a simple diagram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flowchart.png](../data/figs/platform_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get started with the SSD example, make sure that you have the checkpoint files of your model and a `plumber_cli` installed in your virtual environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can simply use the `plumber_cli` to step-by-step to create a DFG that can be loaded on FPGA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Step: Freezing a model\n",
    "Make sure that your checkpoint files generated after training/retrraining session contain these files: \n",
    "\n",
    "`checkpoint`: a file that contains meta information, data fines and index file about the checkpoint directory.\n",
    "\n",
    "`*.meta`: the meta information about your model\n",
    "\n",
    "`*.data`: weights data\n",
    "\n",
    "`*.index`: the index file\n",
    "\n",
    "These files are now going to be used to be imported into `plumber` and consequently converted into a representation that the platform *understands* and can optimise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ plumber_cli freeze /tmp/ssd_ckpt -d /tmp/ssd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`/tmp/ssd_ckpt`: is the checkpoint directory\n",
    "\n",
    "`/tmp/ssd`: is the output directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Step: Creating a DFG\n",
    "\n",
    "Out of these files that you have created you can create a raw Data-Flow graph, again by using `plumber_cli`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ plumber_cli dfg /tmp/ssd.pb /tmp/ssd_dfg.pb --dfg-text-file=/tmp/ssd_dfg.pbtxt --dfg-data-file=/tmp/ssd_dfg.h5 --input-image-shape=1,256,256,3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`/tmp/ssd.pb`: is the plumber file describing the network as a plumber binary file\n",
    "\n",
    "`/tmp/ssd_dfg.pb`: is the plumber template for a DFG\n",
    "\n",
    "`/tmp/ssd_dfg.pbtxt`: is the description of the DFG in a text format\n",
    "\n",
    "`/tmp/ssd_dfg.h5`: is a data-file describing input/output sizes, important for random data generation or weights extraction\n",
    "\n",
    "`1,256,256,3`: is an input image shape, in our case 256x256 images with three channels with one image per batch, n.b.: the format is Batch Size, Height, Width, Number of Channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step: Optimizing DFG\n",
    "`plumber` has the ability to compotationally optimise the DFG with respect to the hardware that the platform presents, that can result in increased accuracy and speed improvements.\n",
    "\n",
    "You can do it simply with `plumber_cli`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ plumber_cli dfg_opt --dfg-file=/tmp/ssd_dfg.pb --dfg-data-file=/tmp/ssd_dfg.h5 --opt-dfg-file=/tmp/ssd_opt_dfg.pbtxt --logdir=/tmp/logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will now take the original DFG described in `tmp/ssd_dfg.pb` and optimize it to maximaise the gain from our platform: \n",
    "\n",
    "`/tmp/ssd_dfg.pb`: is the plumber file describing the network as a plumber binary file\n",
    "\n",
    "`/tmp/ssd_dfg.h5`: is the data file that we have created in the previous step\n",
    "\n",
    "`/tmp/ssd_opt_dfg.pbtxt`: this is the new, optimised, pbtxt\n",
    "\n",
    "`/tmp/logs`: this is the logging directory\n",
    "\n",
    "now let's move to the next step, which actually results in an execution on embedded system with FPGA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to skip these two steps you can also find the data generated at this link: [Link](https://s3-eu-west-1.amazonaws.com/coreraincifardata/ssd_6b_data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step: Importing DFG into `raintime`\n",
    "\n",
    "Just as a quick recap: `raintime` is a software runtime library for processing CNNs on embedded FPGA systems. Computation nodes in a CNN can either be processed in CPU or offloaded to the FPGA accelerator design built by `rainman`. It also has several parts, it can be summarised in a diagram without going to detail: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![raintime.png](../data/figs/raintime.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes themselves are already implemented in raintime, but we need to streamline the execution and say which data we want to extract etc. In later versions this step is going to be completely automatic, at the moment we have to write a short demo.\n",
    "\n",
    "If we were about to write the demo in `raintime`, to execute the demo on FPGA it would have several important steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C++\n",
    "  int batch_size = 1;\n",
    "  int n_channels = 3;\n",
    "  int img_size = 265\n",
    "\n",
    "  // Load image\n",
    "  cv::Mat image;\n",
    "    image = cv::imread(argv[1], cv::CV_LOAD_IMAGE_COLOR);\n",
    "    \n",
    "  // Reorder the pixel values from the default ordering of opencv\n",
    "  std::vector<uint8_t> converted;\n",
    "  auto image_pointer = image.ptr();\n",
    "  for (size_t i = 0; i < n_channels; i++) {\n",
    "    for (size_t j = 0; j < img_size * img_size; j++) {\n",
    "      converted[j + img_size * img_size * i] =  image[n_channels * j + i];\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Load DFGDef\n",
    "  auto dfg_def = LoadDFGDefFromFile(dfg_file_name);\n",
    "\n",
    "  // Use the integrated builder to build the graph and make abstractions to connect the CPU and FPGA\n",
    "  *dfg = DFGBuilder(dfg_def).Build();\n",
    "\n",
    "  // Load constant data map, including weights and biases\n",
    "  *data_map = new DFGDataMap;\n",
    "  (*data_map)->LoadFromDir(data_dir);\n",
    "  \n",
    "  \n",
    "  std::vector<int> dims;\n",
    "  dims.push_back(n_channels);\n",
    "  dims.push_back(img_size);\n",
    "  dims.push_back(img_size);\n",
    "  dims.push_back(batch_size);\n",
    "  \n",
    "  \n",
    "  // Load input data-map into the DFG, without any particular pre-processing optimisations\n",
    "  DFGDataMap *input_data_map = new DFGDataMap;\n",
    "    input_data_map->LoadImage(converted, image_size, n_channels,\n",
    "                              \"input_tensor\", dims, \"no\");\n",
    "                              \n",
    "  // Extract the output data map from the runner, in this case the \n",
    "  auto output_data_map = runner->Run(dfg, data_map, input_data_map, true);\n",
    "  auto output_data = output_data_map->get(\"Predictions\").second;\n",
    "\n",
    "\n",
    "  std::cout<<\"The number of detected faces: \"<<output_data_map.size()<<std::endl;\n",
    "  \n",
    "  //House-keeping\n",
    "  delete input_data_map;\n",
    "  delete output_data_map;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished writing the demo, then you would have to compile your design, on the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compilation\n",
    "\n",
    "This is fairly easy, `raintime` has several settings how to compile a project, but we will try to avoid details. Once connected to the board with preinstalled OS and a correct `BOOT.bin`, you would clone the raintime project with your demo and compile it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ git clone https://github.com/corerain/raintime.git\n",
    "$ cd raintime\n",
    "$ mkdir build && cd build\n",
    "# Create the compiling structure through CMake and specify the number of fraction bits (FB) for a 32 bit representation\n",
    "$ cmake .. -DCMAKE_BUILD_TYPE=Release -DDEF_FIXED_NUM_FB_32=20 -DBUILD_TESTS=ON\n",
    "$ make\n",
    "$ ./ssd_6b_demo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and viola! You have described an algorithm in Python/Tensorflow and now you are executing it on FPGA, great isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The process up-to raintime is also available as a web-application on: [Link](http://corerain1.corerain.com:5005/), where you can not only view the SSD demo but also others. Below is the team with behind the platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![team.jpeg](../data/figs/team.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Or you can see a video of hte demonstration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"../data/figs/face_detecion.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"../data/figs/face_detecion.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
