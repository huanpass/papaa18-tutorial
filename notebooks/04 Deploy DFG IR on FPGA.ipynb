{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy DFG IR on FPGA\n",
    "\n",
    "This tutorial continues, with how to, finally deploy the algorithm, in this case the simple CNN trained on the MNIST dataset, onto an FPGA. We have talked about the network itself, Tensorflow as a *DSL* and we are going to finish off by using the platform that we have introduced in previous tutorials to take this network and actually deploy it onto the FPGA.\n",
    "\n",
    "Given that you have installed `plumber` in the Tutorial 1, we are now going to use it to generate a *D*ata-*F*low *G*raph (DFG) that can be passed down the platform to reach the final execution on FPGA and CPU. \n",
    "\n",
    "Just for a quick summary, the platform itself consists of multiple parts: *plumber* is a web-based application capable of taking a templated description of a machine learning algorithm, optimize it and create a DFG that is then passed into *raintime*. *raintime* then instantiates computation nodes, either processed in a CPU or offloaded to a FPGA accelerator. *rainman* then takes the FPGA templates and synthesises them on the device itself, while interconnecting with the nodes instantiated on the CPU. All can be visualised in a simple diagram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flowchart.png](../data/figs/platform_flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get started with the MNIST example, make sure that you have the checkpoint files of your model and a `plumber_cli` installed in your virtual environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can simply use the `plumber_cli` to step-by-step to create a DFG that can be loaded on FPGA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Step: Freezing a model\n",
    "Make sure that your checkpoint files generated after training/retrraining session contain these files: \n",
    "\n",
    "`checkpoint`: a file that contains meta information about the checkpoint directory.\n",
    "\n",
    "`*.meta`: the meta information about your model\n",
    "\n",
    "`*.data`: weights data\n",
    "\n",
    "`*.index`: the index file\n",
    "\n",
    "These files are now going to be used to be imported into `plumber` and consequently converted into a representation that the platform *understands* and can optimise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ plumber_cli freeze /tmp/mnist_lenet_ckpt -d /tmp/mnist_lenet -o Lenet/argmax\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`/tmp/mnist_lenet_ckpt`: is the checkpoint directory\n",
    "\n",
    "`/tmp/mnist_lenet`: is the output directory\n",
    "\n",
    "`Lenet/argmax`: is the last layer, that can be provided or automatically infered from the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Step: Creating a DFG\n",
    "\n",
    "Out of these files that you have created you can create a raw Data-Flow graph, again by using `plumber_cli`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ plumber_cli dfg /tmp/mnist_lenet.pb /tmp/mnist_lenet_dfg.pb --dfg-text-file=/tmp/mnist_lenet_dfg.pbtxt --dfg-data-file=/tmp/mnist_lenet_dfg.h5 --input-image-shape=1,28,28,1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`/tmp/mnist_lenet.pb`: is the plumber file describing the network as a plumber binary file\n",
    "\n",
    "`/tmp/mnist_lenet_dfg.pb`: is the plumber template for a DFG\n",
    "\n",
    "`/tmp/mnist_lenet_dfg.pbtxt`: is the description of the DFG in a text format\n",
    "\n",
    "`/tmp/mnist_lenet_dfg.h5`: is a data-file describing input/output sizes, important for random data generation or weights extraction\n",
    "\n",
    "`1,28,28,1`: is an input image shape, in our case 28x28 images with one channel with one batch, n.b.: the format is Batch Size, Height, Width, Number of Channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step: Optimizing DFG\n",
    "`plumber` has the ability to compotationally optimise the DFG with respect to the hardware that the platform presents, that can result in increased accuracy and speed improvements.\n",
    "\n",
    "You can do it simply with `plumber_cli`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ plumber_cli dfg_opt --dfg-file=/tmp/mnist_lenet_dfg.pb --dfg-data-file=/tmp/mnist_lenet_dfg.h5 --opt-dfg-file=/tmp/mnist_lenet_opt_dfg.pbtxt --logdir=/tmp/logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will now take the original DFG described in `tmp/mnist_lenet_dfg.pb` and optimize it to maximaise the gain from our platform: \n",
    "\n",
    "`/tmp/mnist_lenet_dfg.pb`: is the plumber file describing the network as a plumber binary file\n",
    "\n",
    "`/tmp/mnist_lenet_dfg.h5`: is the data file that we have created in the previous step\n",
    "\n",
    "`/tmp/mnist_lenet_opt_dfg.pbtxt`: this is the new, optimised, pbtxt\n",
    "\n",
    "`/tmp/logs`: this is the logging directory\n",
    "\n",
    "now let's move to the next step, which actually results in an execution on embedded system with FPGA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to skip these two steps you can also find the data generated at this link: [Link](https://s3.eu-west-2.amazonaws.com/raintime-test-data/mnist_data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step: Importing DFG into `raintime`\n",
    "\n",
    "Just as a quick recap: `raintime` is a software runtime library for processing CNNs on embedded FPGA systems. Computation nodes in a CNN can either be processed in CPU or offloaded to the FPGA accelerator design built by `rainman`. It also has several parts, it can be summarised in a diagram without going to detail: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![raintime.png](../data/figs/raintime.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes themselves are already implemented in raintime, but we need to streamline the execution and say which data we want to extract etc. In later versions this step is going to be completely automatic, at the moment we have to write a short demo.\n",
    "\n",
    "If we were about to write the demo in `raintime`, to execute the demo on FPGA it would have several important steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C++\n",
    "\n",
    "  //Initialize the dataset and the score\n",
    "  dataset = new raintime::dataset::MNISTDataset<>(\n",
    "        std::string(dataset_dir) + \"/train-images.idx3-ubyte\",\n",
    "        std::string(dataset_dir) + \"/train-labels.idx1-ubyte\",\n",
    "        std::string(dataset_dir) + \"/t10k-images.idx3-ubyte\",\n",
    "        std::string(dataset_dir) + \"/t10k-labels.idx1-ubyte\");\n",
    "  int score = 0;\n",
    "  \n",
    "  // Load DFGDef\n",
    "  auto dfg_def = LoadDFGDefFromFile(dfg_file_name);\n",
    "\n",
    "  // Use the integrated builder to build the graph and make abstractions to connect the CPU and FPGA\n",
    "  *dfg = DFGBuilder(dfg_def).Build();\n",
    "\n",
    "  // Load constant data map, including weights and biases\n",
    "  *data_map = new DFGDataMap;\n",
    "  (*data_map)->LoadFromDir(data_dir);\n",
    "  \n",
    "  \n",
    "  // Load input data-map\n",
    "  DFGDataMap *input_data_map = new DFGDataMap;\n",
    "    input_data_map->LoadImage(dataset->GetTestImage(i).data(), 28, n_channels,\n",
    "                              \"placeholder_0\", dims, \"mean\");\n",
    "                              \n",
    "  // Extract the output data map from the runner, in this case the \n",
    "  auto output_data_map = runner->Run(dfg, data_map, input_data_map, true);\n",
    "  auto output_data = output_data_map->get(\"Predictions\").second;\n",
    "\n",
    "  // Perform ArgMax operation, in this demo thsi node was not defined\n",
    "  int index = -1;\n",
    "  float maximum = -1;\n",
    "  for (size_t j = 0; j < classes; j++) {\n",
    "    if ((float)output_data->at(j) > maximum) {\n",
    "      maximum = (float)output_data->at(j);\n",
    "      index = j;\n",
    "    }\n",
    "  }\n",
    "  label = index;\n",
    "  golden_label = dataset->GetTestLabel(i);\n",
    "  \n",
    "  score += label == golden_label;\n",
    "  \n",
    "  //House-keeping\n",
    "  delete input_data_map;\n",
    "  delete output_data_map;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have finished writing the demo, then you would have to compile your design, on the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compilation\n",
    "\n",
    "This is fairly easy, `raintime` has several settings how to compile a project, but we will try to avoid details. Once connected to the board with preinstalled OS and a correct `BOOT.bin`, you would clone the raintime project with your demo and compile it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ git clone https://github.com/corerain/raintime.git\n",
    "$ cd raintime\n",
    "$ mkdir build && cd build\n",
    "# Create the compiling structure through CMake and specify the number of fraction bits (FB) for a 32 bit representation\n",
    "$ cmake .. -DCMAKE_BUILD_TYPE=Release -DDEF_FIXED_NUM_FB_32=20\n",
    "$ make\n",
    "$ ./eval_mnist\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and viola! You have described an algorithm in Python/Tensorflow and now you are executing it on FPGA, great isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extra\n",
    "MNIST is of course a toy example, but our platform can compile and execute much more complicated architectures like [Singe-Shot MultiBox Detection](https://arxiv.org/abs/1512.02325) (SSD) to perform face-detection. This architecture is ideal for embedded devices, because it does not need extensive resources to perform the detection/classification. \n",
    "\n",
    "The process up-to raintime is also available as a web-application on: [Link](http://corerain1.corerain.com:5005/), where you can not only view the MNIST demo but also the SSD demo. Below is the team with behind the platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![team.jpeg](../data/figs/team.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
